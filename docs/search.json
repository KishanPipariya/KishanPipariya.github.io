[
  {
    "objectID": "posts/kmeans_demo/kmeans.html",
    "href": "posts/kmeans_demo/kmeans.html",
    "title": "k-means",
    "section": "",
    "text": "import matplotlib.pyplot as plt # To make visualisations\nfrom sklearn.cluster import KMeans #To perform K-Means clustering\nfrom sklearn.cluster import DBSCAN \nfrom sklearn.datasets import make_blobs #To generate data for kmeans\nfrom sklearn.datasets import make_moons #To generate data for DBSCAN\n\n\nX, y = make_blobs(n_samples=300, centers=4, cluster_std=0.9, random_state=42)\n\n\nX.shape #Collection of points in 2D space\n\n(300, 2)\n\n\n\nX_coord = X[:, 0] #X coordinates of the points\nY_coord = X[:, 1] #Y coordinates of the points\n\nprint(X_coord[:5])\nprint(Y_coord[:5])\n\n[ -9.25175257  -9.61269979  -1.7689072   -7.07554027 -10.67263984]\n[ 6.55866298  6.97742293  7.91552684 -5.89121043  6.41624524]\n\n\n\nplt.scatter(X_coord, Y_coord, s=50, c='blue');\n\n\n\n\n\n\n\n\n\n\nkmeans = KMeans(n_clusters=4, n_init='auto') #N_init refers to the number of times the clustering algo is ran\nkmeans.fit(X)\ny_pred = kmeans.predict(X)\ny_pred\n\narray([1, 1, 3, 2, 1, 2, 0, 2, 3, 0, 3, 0, 3, 3, 1, 3, 1, 0, 3, 3, 0, 3,\n       2, 1, 3, 1, 1, 2, 2, 0, 3, 0, 1, 0, 1, 3, 1, 2, 1, 2, 0, 3, 1, 2,\n       3, 3, 1, 0, 1, 0, 2, 1, 2, 3, 2, 0, 1, 0, 0, 3, 1, 0, 0, 1, 2, 2,\n       2, 2, 2, 3, 2, 2, 1, 0, 3, 1, 2, 2, 3, 2, 3, 3, 1, 3, 2, 1, 1, 0,\n       0, 0, 1, 3, 1, 3, 3, 1, 2, 3, 1, 1, 0, 0, 0, 3, 3, 3, 3, 3, 2, 1,\n       0, 3, 3, 3, 3, 0, 1, 2, 1, 2, 2, 2, 3, 1, 2, 1, 1, 3, 1, 2, 0, 3,\n       3, 3, 3, 0, 0, 1, 3, 2, 3, 0, 2, 3, 0, 0, 0, 0, 2, 3, 3, 1, 0, 2,\n       3, 0, 2, 1, 1, 0, 3, 1, 2, 1, 0, 1, 2, 3, 3, 3, 3, 3, 2, 0, 0, 2,\n       2, 0, 0, 2, 1, 3, 1, 0, 0, 1, 2, 3, 0, 0, 2, 2, 2, 1, 0, 2, 2, 0,\n       0, 1, 3, 3, 2, 0, 3, 2, 2, 1, 2, 3, 3, 2, 2, 0, 1, 2, 1, 1, 3, 1,\n       1, 2, 1, 2, 0, 0, 1, 1, 0, 0, 0, 1, 3, 2, 0, 2, 1, 0, 1, 1, 1, 2,\n       2, 0, 1, 2, 2, 2, 1, 2, 1, 2, 1, 0, 2, 1, 0, 3, 1, 3, 0, 3, 1, 3,\n       2, 0, 2, 0, 0, 3, 3, 2, 0, 0, 1, 1, 2, 3, 3, 0, 0, 0, 0, 2, 1, 0,\n       2, 0, 0, 2, 3, 2, 0, 3, 1, 3, 0, 3, 1, 1], dtype=int32)\n\n\n\nplt.scatter(X_coord, Y_coord, s=50, c=y_pred, cmap='viridis')\n\ncenters = kmeans.cluster_centers_ # Gets the coordinates of the cluster centers\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=100);\n\n\n\n\n\n\n\n\nLink to a visualisation site: https://www.naftaliharris.com/blog/visualizing-k-means-clustering/\n\nIs k-means the perfect option for all cases?\n\nX, y = make_moons(n_samples=300, noise=0.05, random_state=42)\n\n\nkmeans = KMeans(n_clusters=2, n_init='auto', random_state=42)\nlabels = kmeans.fit_predict(X)\nprint(labels.shape)\n\n(300,)\n\n\n\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=50, cmap='viridis');\ncenters = kmeans.cluster_centers_\nplt.scatter(centers[:, 0], centers[:, 1], c='black', s=100);\n\n\n\n\n\n\n\n\n\nTo overcome this issue we use other clustering algorithm such as DBSCAN\n\ndbscan = DBSCAN(eps=0.3, min_samples=2).fit(X)\nlabels = dbscan.labels_\nplt.scatter(X[:, 0], X[:, 1], c=labels, s=50, cmap='viridis');\n\n\n\n\n\n\n\n\nLink to a visualisation site: https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Kishanâ€™s home on the Internet",
    "section": "",
    "text": "k-means\n\n\n\n\n\n\ncode\n\n\n\nA short demo on k-means\n\n\n\n\n\nJan 15, 2024\n\n\nKishan Pipariya\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "A place to share my ideas with the world."
  }
]